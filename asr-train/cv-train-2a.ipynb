{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ddd02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: torch==2.1.0+cu118 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from torchaudio) (2.1.0+cu118)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from torch==2.1.0+cu118->torchaudio) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from torch==2.1.0+cu118->torchaudio) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from torch==2.1.0+cu118->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from torch==2.1.0+cu118->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (79.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: rich in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from sympy->torch==2.1.0+cu118->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "Successfully installed huggingface-hub-0.30.2\n",
      "Requirement already satisfied: datasets in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tf-keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (79.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.9)\n",
      "Requirement already satisfied: optree in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (2.1.0+cu118)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->transformers[torch]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cheny\\anaconda3\\envs\\py311\\lib\\site-packages (from sympy->torch>=2.0->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torchaudio tensorflow librosa matplotlib \n",
    "!pip install datasets\n",
    "!pip install datasets\n",
    "!pip install tf-keras\n",
    "!pip install transformers[torch]\n",
    "#!pip install numpy<2.0\n",
    "#!pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39252f2a-f1be-4b44-a67b-af90f95ac49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, Audio\n",
    "import transformers\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b73d4de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filename', 'text', 'up_votes', 'down_votes', 'age', 'gender', 'accent',\n",
      "       'duration', 'path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "audio_dir = r\"C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid-train\"\n",
    "csv_file_path = r\"C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid-train.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Construct full paths to MP3 files\n",
    "df[\"path\"] = df[\"filename\"].apply(lambda x: os.path.join(audio_dir, x))\n",
    "\n",
    "# Check column names\n",
    "print(df.columns)\n",
    "\n",
    "# Train-validation split\n",
    "train_df, val_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "# Cast audio column to `Audio`\n",
    "train_dataset = train_dataset.cast_column(\"path\", Audio())\n",
    "val_dataset = val_dataset.cast_column(\"path\", Audio())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3621cb90-2651-454a-a0f4-3ad518ca5109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3183e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import torch\n",
    "import torchaudio\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"preprocessing_errors.log\", level=logging.WARNING)\n",
    "\n",
    "def preprocess(example):\n",
    "    try:\n",
    "        audio = example[\"path\"]\n",
    "        waveform = audio[\"array\"]\n",
    "        sampling_rate = audio[\"sampling_rate\"]\n",
    "\n",
    "        # Resample if needed\n",
    "        if sampling_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "            waveform = resampler(torch.tensor(waveform).float()).numpy()\n",
    "\n",
    "        # Encode input\n",
    "        input_values = processor(waveform, sampling_rate=16000, return_tensors=\"pt\").input_values[0]\n",
    "\n",
    "        # Encode label\n",
    "        labels = processor.tokenizer(\n",
    "            example[\"text\"],\n",
    "            add_special_tokens=False\n",
    "        ).input_ids\n",
    "\n",
    "        return {\n",
    "            \"input_values\": input_values,\n",
    "            \"labels\": torch.tensor(labels)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to process: {example.get('path', 'unknown')} â€” {str(e)}\")\n",
    "        return None  # return nothing if it fails\n",
    "\n",
    "# Manually process train_dataset row-by-row\n",
    "processed_train = []\n",
    "for i, example in enumerate(train_dataset):\n",
    "    result = preprocess(example)\n",
    "    if result is not None:\n",
    "        processed_train.append(result)\n",
    "\n",
    "processed_val = []\n",
    "for i, example in enumerate(val_dataset):\n",
    "    result = preprocess(example)\n",
    "    if result is not None:\n",
    "        processed_val.append(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21762c35-9c7f-4c5f-a4d4-54de8b8aa0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new datasets\n",
    "train_dataset = Dataset.from_list(processed_train)\n",
    "val_dataset = Dataset.from_list(processed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4007c-cfdc-41d5-a25c-5ae4b372a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3928bb03-8aa1-480b-8ecf-01247abc2080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e261bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 156])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheny\\anaconda3\\envs\\py311\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c459bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheny\\anaconda3\\envs\\py311\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_values': tensor([[[0.0015, 0.0015, 0.0015,  ..., 0.0015, 0.0015, 0.0015]]])}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f2c0a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample paths:\n",
      " 0    C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid...\n",
      "1    C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid...\n",
      "2    C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid...\n",
      "3    C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid...\n",
      "4    C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid...\n",
      "Name: path, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./wav2vec2-large-960h-cv\")\n",
    "processor.save_pretrained(\"./wav2vec2-large-960h-cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46784b06-89f5-4af0-83e8-c8d98b860bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logs = trainer.state.log_history\n",
    "train_loss = [log[\"loss\"] for log in logs if \"loss\" in log]\n",
    "eval_loss = [log[\"eval_loss\"] for log in logs if \"eval_loss\" in log]\n",
    "\n",
    "plt.plot(train_loss, label=\"Train Loss\")\n",
    "plt.plot(eval_loss, label=\"Eval Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Evaluation Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cddc5eb-f5c8-4dab-b024-0100fc8c82f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c4ac4489ca4582982a02a8411ee201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/137043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Wav2Vec2CTCTokenizer(name_or_path='facebook/wav2vec2-large-960h', vocab_size=32, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken(\"<pad>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n\t1: AddedToken(\"<s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n\t2: AddedToken(\"</s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n\t3: AddedToken(\"<unk>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n}\n) got multiple values for keyword argument 'return_attention_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Apply preprocessing to datasets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_dataset = \u001b[43mtrain_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m val_dataset = val_dataset.map(preprocess, remove_columns=val_dataset.column_names)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Training arguments\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\datasets\\arrow_dataset.py:557\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m self_format = {\n\u001b[32m    551\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    552\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    553\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    555\u001b[39m }\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    558\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3074\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[39m\n\u001b[32m   3068\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3069\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[32m   3070\u001b[39m         unit=\u001b[33m\"\u001b[39m\u001b[33m examples\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3071\u001b[39m         total=pbar_total,\n\u001b[32m   3072\u001b[39m         desc=desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3073\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m3074\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3492\u001b[39m, in \u001b[36mDataset._map_single\u001b[39m\u001b[34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[39m\n\u001b[32m   3490\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[32m   3491\u001b[39m     _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m3492\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3494\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3466\u001b[39m, in \u001b[36mDataset._map_single.<locals>.iter_outputs\u001b[39m\u001b[34m(shard_iterable)\u001b[39m\n\u001b[32m   3464\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3465\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[32m-> \u001b[39m\u001b[32m3466\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\datasets\\arrow_dataset.py:3389\u001b[39m, in \u001b[36mDataset._map_single.<locals>.apply_function\u001b[39m\u001b[34m(pa_inputs, indices, offset)\u001b[39m\n\u001b[32m   3387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[32m   3388\u001b[39m inputs, fn_args, additional_args, fn_kwargs = prepare_inputs(pa_inputs, indices, offset=offset)\n\u001b[32m-> \u001b[39m\u001b[32m3389\u001b[39m processed_inputs = \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3390\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mpreprocess\u001b[39m\u001b[34m(example)\u001b[39m\n\u001b[32m     12\u001b[39m     waveform = resampler(torch.tensor(waveform).float()).numpy()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Encode input audio\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m input_values = \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.input_values[\u001b[32m0\u001b[39m]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Encode labels directly using tokenizer without return_attention_mask\u001b[39;00m\n\u001b[32m     18\u001b[39m labels = processor.tokenizer(\n\u001b[32m     19\u001b[39m     example[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     20\u001b[39m     add_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     21\u001b[39m ).input_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\transformers\\models\\wav2vec2\\processing_wav2vec2.py:104\u001b[39m, in \u001b[36mWav2Vec2Processor.__call__\u001b[39m\u001b[34m(self, audio, text, images, videos, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# For backward compatibility\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_processor(\n\u001b[32m    105\u001b[39m         audio,\n\u001b[32m    106\u001b[39m         **output_kwargs[\u001b[33m\"\u001b[39m\u001b[33maudio_kwargs\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    107\u001b[39m         **output_kwargs[\u001b[33m\"\u001b[39m\u001b[33mtext_kwargs\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    108\u001b[39m         **output_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcommon_kwargs\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    109\u001b[39m     )\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    112\u001b[39m     inputs = \u001b[38;5;28mself\u001b[39m.feature_extractor(audio, **output_kwargs[\u001b[33m\"\u001b[39m\u001b[33maudio_kwargs\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mTypeError\u001b[39m: Wav2Vec2CTCTokenizer(name_or_path='facebook/wav2vec2-large-960h', vocab_size=32, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t0: AddedToken(\"<pad>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n\t1: AddedToken(\"<s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n\t2: AddedToken(\"</s>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n\t3: AddedToken(\"<unk>\", rstrip=True, lstrip=True, single_word=False, normalized=False, special=False),\n}\n) got multiple values for keyword argument 'return_attention_mask'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea03d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718fa5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from jiwer import wer\n",
    "\n",
    "# Load the model and processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"wav2vec2-large-960h-cv\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"wav2vec2-large-960h-cv\")\n",
    "\n",
    "# Load test data\n",
    "test_csv_file_path = r'C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid-test.csv'\n",
    "test_df = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Directory containing test audio files\n",
    "test_audio_dir = r'C:\\Users\\cheny\\Downloads\\common_voice\\cv-valid-test\\'\n",
    "\n",
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# Loop over each row in the CSV to get the test files and their ground truth\n",
    "for index, row in test_df.iterrows():\n",
    "    audio_file = os.path.join(test_audio_dir, row['filename'])\n",
    "    ground_truth = row['transcription']\n",
    "\n",
    "    # Transcribe the audio file\n",
    "    transcription = transcribe_audio(audio_file)\n",
    "    \n",
    "    # Calculate WER\n",
    "    wer_score = wer(ground_truth, transcription)\n",
    "\n",
    "    # Append the results\n",
    "    results.append({\n",
    "        'filename': row['filename'],\n",
    "        'ground_truth': ground_truth,\n",
    "        'transcription': transcription,\n",
    "        'wer': wer_score\n",
    "    })\n",
    "\n",
    "# Convert results into a DataFrame for easy inspection\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results (or save to a file)\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save results to a CSV file\n",
    "results_df.to_csv('transcription_results.csv', index=False)\n",
    "\n",
    "# Calculate the min, max, and average WER\n",
    "min_wer = results_df['wer'].min()\n",
    "max_wer = results_df['wer'].max()\n",
    "average_wer = results_df['wer'].mean()\n",
    "\n",
    "# Print the min, max, and average WER\n",
    "print(f\"Min WER: {min_wer:.4f}\")\n",
    "print(f\"Max WER: {max_wer:.4f}\")\n",
    "print(f\"Average WER: {average_wer:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac46cfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06bada1e",
   "metadata": {},
   "source": [
    "Adapted from ChatGPT: \n",
    "\n",
    "Explanation for Preprocessing, Tokenizer, Feature Extraction, and Pipeline Processes\n",
    "\n",
    "In this section, I'll explain the choices I made for preprocessing, tokenizer, feature extraction, and pipeline processes for fine-tuning an Automatic Speech Recognition (ASR) model using the Common Voice dataset. Additionally, I'll describe the hyperparameters used for training and what the training/validation metrics mean.\n",
    "\n",
    "1. Preprocessing\n",
    "Why Preprocessing Is Necessary: Preprocessing ensures that the audio data is in a suitable format for the model to understand. It involves steps like loading the audio, resampling to a fixed sample rate, and ensuring consistency in the audio input format.\n",
    "\n",
    "The original dataset contains audio with varying sample rates. To ensure consistency, I resampled all audio files to a fixed sample rate of 16kHz. This is the standard used by many ASR models, including Wav2Vec2, as it balances computational efficiency and audio quality.\n",
    "\n",
    "2. Tokenizer\n",
    "Why We Use a Tokenizer: The tokenizer converts text data (the transcription of the audio) into numerical representations that the model can work with. Since Wav2Vec2 uses CTC (Connectionist Temporal Classification) loss, it requires a tokenizer that can map the transcription to labels and vice versa.\n",
    "\n",
    "Wav2Vec2Processor: This processor from Hugging Face's transformers library automatically handles both feature extraction from audio and tokenization of transcriptions.\n",
    "\n",
    "The processor:\n",
    "Tokenizes the transcription (text) into input_ids.\n",
    "Converts audio into features that are suitable for the Wav2Vec2 model.\n",
    "\n",
    "3. Feature Extraction\n",
    "Why Feature Extraction Is Necessary:\n",
    "Wav2Vec2 works directly with raw audio waveforms, but we can also extract spectrograms to enhance performance in some cases.\n",
    "However, in this case, we will use the Wav2Vec2Processor, which includes feature extraction as part of the preprocessing pipeline. The processor:\n",
    "Extracts Mel-frequency cepstral coefficients (MFCCs) or raw waveforms.\n",
    "Normalizes the input for consistency in processing.\n",
    "Converts raw waveforms into suitable input for Wav2Vec2.\n",
    "\n",
    "4. Pipeline\n",
    "The pipeline consists of several steps that convert raw data into a form suitable for training a deep learning model.\n",
    "\n",
    "Pipeline Components:\n",
    "Load Audio: Use torchaudio to read audio files.\n",
    "Resample Audio: Resample all audio to 16kHz to maintain consistency.\n",
    "Feature Extraction: Convert the waveform to Mel Spectrogram or raw audio features.\n",
    "Tokenization: Use the Wav2Vec2Processor to handle both feature extraction and transcription tokenization.\n",
    "Model Training: Feed the processed audio and transcription into the model for training.\n",
    "Validation: Split the dataset into training (70%) and validation (30%) sets. Validate on a separate subset during training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33a51f-f27d-49d9-94aa-b22b213bdd5a",
   "metadata": {},
   "source": [
    "5. Hyperparameters for Model Training\n",
    "Below are the selected hyperparameters and the reasoning behind their configuration for fine-tuning wav2vec2-large-960h on the Common Voice dataset:\n",
    "\n",
    "Learning Rate (2e-5):\n",
    "A low learning rate is recommended when fine-tuning pre-trained models like Wav2Vec2 to avoid overwriting pre-trained knowledge. A value of 2e-5 strikes a balance between learning efficiently and preserving previously acquired representations, as suggested by the official Hugging Face documentation.\n",
    "\n",
    "Batch Size (8):\n",
    "We use a batch size of 8 per device, which provides a good trade-off between memory efficiency and training stability. Since audio data can vary in length and can be memory-intensive, especially in 16 kHz resolution, this size ensures that training remains within GPU memory limits.\n",
    "\n",
    "Number of Epochs (3):\n",
    "A small number of training epochs is generally sufficient for fine-tuning on a moderately sized dataset. We selected 3 epochs to allow enough updates for learning, while keeping training time reasonable. Further tuning or early stopping could be applied if needed.\n",
    "\n",
    "Evaluation Strategy (\"epoch\"):\n",
    "We evaluate the model at the end of every epoch to track performance on the validation set. This provides insights into whether the model is improving and helps detect overfitting early.\n",
    "\n",
    "Save Strategy (\"epoch\"):\n",
    "Instead of saving every few steps, the model is saved at the end of each epoch. This is less frequent but aligns well with our evaluation frequency and simplifies checkpoint management.\n",
    "\n",
    "Logging Steps (10):\n",
    "Training logs are recorded every 10 steps. This provides enough granularity to visualize learning trends in real-time without overwhelming the log output.\n",
    "\n",
    "Data Collator (DataCollatorCTCWithPadding):\n",
    "We use Hugging Faceâ€™s DataCollatorCTCWithPadding to dynamically pad audio and label sequences during training. This ensures efficient and correct batching of variable-length input audio and transcriptions.\n",
    "\n",
    "6. Visualizing Training and Validation Metrics\n",
    "After training, we visualize the loss metrics to understand how the model learned over time and evaluate the quality of training and generalization.\n",
    "\n",
    "Loss Curves:\n",
    "Both training and validation losses are plotted across epochs. This helps us visually track how well the model is fitting the data.\n",
    "\n",
    "Interpretation of Loss Curves\n",
    "Training Loss:\n",
    "A steadily decreasing training loss typically indicates that the model is learning effectively. In our case, training loss decreased across epochs, showing that the model was optimizing its internal parameters.\n",
    "\n",
    "Validation Loss:\n",
    "The validation loss reflects how well the model generalizes to unseen data. Ideally, it should decrease in parallel with training loss. If it increases while training loss decreases, itâ€™s a signal that the model is beginning to overfit.\n",
    "\n",
    "Convergence:\n",
    "In our training, both curves show a consistent downward trend, suggesting that the model is converging.\n",
    "\n",
    "Overfitting Signs:\n",
    "We monitor for signs of overfitting, such as a divergence between training and validation loss. If such divergence had occurred, we could reduce the number of epochs or implement early stopping strategies to mitigate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26b6ba-837a-460b-8b75-7d06e2f91e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8cc72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
